{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Neural_Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mopheiok/WatermelonCamp/blob/master/05_Neural_Networks/05_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K3OMfnkgIqhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 试述将线性函数$f(x)=w^Tx$用作神经元激活函数的缺陷"
      ]
    },
    {
      "metadata": {
        "id": "33GLTVUAJB1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "首先，激活函数是用来加入非线性因素的，因为线性模型的表达能力不够。\n",
        "其次，如果仅使用线性函数作为神经元激活函数，无论多少层的神经网络，都会退化成一个线性回归。如下图所示\n",
        "![替代文字](https://pic4.zhimg.com/7c6e12aed30bf315eed8df6476d7ef7b_r.jpg)\n",
        "\n",
        "输出$y$ 始终是输入$x_1, x_2$的线性组合。\n",
        "\n",
        "最后，激活函数一般会追求以下性质：\n",
        " 1. 非线性，内在反映的是模型的非线性\n",
        " 2. 可微性，以支持梯度下降法等基于微分的优化方法\n",
        " 3. 单调性，以保证单层网络是凸约束，从而存在最优\n",
        " 4. 输出值范围受限，当输出有限时，寻优算法（如梯度下降）变得更加稳定\n",
        " 5. 导数可由原函数计算出，以便重复利用\n",
        " \n",
        " \n",
        " 最常用的激活函数有：\n",
        "  - Sigmoid( 对数几率函数)\n",
        "  - Tanh(双曲正切函数)\n",
        "  - ReLUs(修正线性函数)\n",
        "  - RBF(径向基函数)\n",
        "  - softmax(归一化指数函数)"
      ]
    },
    {
      "metadata": {
        "id": "bbTkztnSC-9I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}